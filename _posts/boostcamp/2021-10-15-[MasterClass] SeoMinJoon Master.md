---
title: "Day_49 [마스터클래스] 서민준 마스터"

categories:
  - Boostcamp_AI_Tech/Week_11/Day_49
tags:
  - 마스터클래스
---

# [마스터클래스] 서민준 마스터

대학교 전공이 토목공학이었음 3학년때 전자 컴퓨터공학으로 전공을 바꾸게 됨

토목공학 분야가 너무 정적인 느낌이어서 컴퓨터공학 같은 경우는 코딩해서 내가 뭔가 바꿀 수 있고 기계를
만지는게 재미가 있었던 것 같음 건물을 지으는 것보다

안전과 관련있어서 보수적인 industry 고 오랜기간동안 숙련을 한다음에 20년차되면 무언가를 리딩하는 분야임

그래서 맞지 않아서 3학년때 전과를 하게되고 전자공학과 컴퓨터공학을 둘다 공부하다가 중간쯤에 있는걸 해야겠다고
생각해서 GPU 와 CPU 를 만들 때 program language 가 있는데 그거에 당시에 재밌을거같아서 계속 파기로하고
졸업하고서도 그쪽 일을 하기로 결정이 된 상태였음

적당히 재밌으면서도 잘 맞는거같다고 생각하고 있었는데

인생의 터닝포인트가 4학년 2학기때 하나의 수업을 듣는데 

![]({{site.url}}/assets/images/af74f57c.png)

강화학습이라기 보다는 AI 의 기본을 가르치는 수업이었음

대학교에서 이 수업을 듣게 되었음 너무 재밌었음

AI 랑 하기로했던거랑 좀 다른건데 AI 를 해야겠다고 결심이 섰음

이걸 어떻게 공부해야할지 모르겠으니까 AI 를 공부하려면 뭘 해야할지 주변에 물어봤음

당시에 조언을 해주신분들의 얘기는 대학원을 가야한다 

졸업을 앞두고 바로 직전에 대학원 준비를 하게 되었음

대학원 준비를 하려면 연구경험이 있어야하는데 졸업하고 회사를 다니면서 학교를 와서 연구를 도와줬는데

![]({{site.url}}/assets/images/b28e27e2.png)

공간이미징 연구였음

딥러닝이 등장하기 전이어서 확률적인 모델을 많이 썼는데 베이지안 모델을 많이 썼음

내가 왔던 장소를 인지하는게 중요한 목표였음

한번 내가 벌써 이미 방문한 곳인데 방문한지 안한지 모르면 맵이 이상해질것이고
방문한걸 알 수 있다면 정확하게 보정을 할 수 있고 이 연구에 참여를 하게되었음

어떤 사람이 공개한 코드가 안돌아가서 돌아가는 한경을 만드는 과정을 도와줬음

이런걸 하다가 운이 좋게도 이때 결과가 linux ubuntu 를 많이 삽질해서 코드를 reproduce 를 하게되었고
이걸 통해서 대학원에 가게 되었음

시애틀에서 대학원 생활을 하기 시작했음

처음에는 비전쪽을 하다보니 비전을 계속하려고 했음

당시 지도교수님이 

![]({{site.url}}/assets/images/d162c5e5.png)

도형문제를 푸는 문제를 줬음

비전관련이라고 생각했음

하다보니 비전 문제보다는 오히려 언어쪽을 더 잘 해야 함

언어를 잘한다는 것도 어렵기도 했지만 이미지보다 언어쪽에 빠져들게 되었음

언어라는 것은 인간이 발명한 것중에 가장 효율적인 커뮤니케이션 툴임

그 매개체를 통해서 정보, 생각, 가르침조차 거의 모든걸 이 매개체를 통해서 하고 이미지가 더해져서 더 쉬운
소통이 되겠지만 거기에 본질적으로는 언어가 있다는 것을 부정할 수 없음

언어라는게 궁극의 문제고 매력적인 문제라고 생각을 하게 되었음

여기서는 추론 능력이 필요하기 때문에 그래서 이 문제를 파고들면서 연구를 하게되었음

운이 좋았다고 생각하는게 딱 그시기에 대학원을 갔다는 점임

딥러닝 바로 직전에 시작해서 딥러닝이 학계와 산업에 모든걸 takeover 하는 걸 직접 볼 수 있었다는게 감사했음

훗날에는 지금 우리가 기억하는 산업혁명처럼 기억하는 시기가 될 수 있음

학습데이터가 너무 적어서 기존 방법론으로 적용해보려했는데 딥러닝이 뜨기 시작하면서 데이터가 많아야 되고
문제가 좀 적당히 어려워야하는데 문제가 너무 어려웠음

![]({{site.url}}/assets/images/7aaa1deb.png)

SQuAD 라는 데이터셋이 나왔는데 10만 개정도의 데이터 example 이었음

이 문제는 그만큼 어렵지는 않지만 데이터개수가 상당히 많고 하고 싶은 일이었음

이 모델이 데이터를 통해서 독해능력을 기를 수 있는가에 관심이 많았고 이 데이터가 상당히 매력적으로 보였음

데이터가 공개된게 2016년 5월 쯤이었는데 하고있던 문제와 비슷했어서 tackle 하기 시작했고

이 데이터가 초창기 NLP 에서는 사람들이 관심을 많이 가지는 데이터가 되었음 물론 그 당시에는 몰랐지만

여름동안에 이 데이터를 잘 하는 모델을 만들었는데 그 모델이 당시에 리더보드에서 1등을 했음

그 때 비슷한 모델들이 있었는데 다른 곳들은 모두 회사였고 오픈소스에 관심이 없었고 교수님은 오픈소스를 바로했음

이 데이터에 대한 관심이 올라가고 관심이 올라가니까 baseline 을 해보려하는데 오픈소스가 없어서 교수님의
모델이 관심을 많이 받았음

이 일을 통해 알려진게 후의 일들이 잘 풀리는 계기가 됨

정말 재밌고 속도가 붙는 느낌으로 빠지는게 있고 앞뒤가 막힌 느낌으로 빠져서 계속 붙잡고 있는 두가지가 있는데

한 스텝 뒤로 물러나서 문제를 바꾸는 방법으로 도움이 되었음

2017년도에 박사과정 중이었는데 네이버에서 좋은 기회가 생겼고 군복무도 같이 할 수 있는 기회라고 해서 네이버로
오게되었음

네이버로 와서 2018년도에 일을 시작했음

네이버에서 느꼈던 것 중에 

클로바가 생긴지 얼마 안된 시점이었음

클로바는 AI 가 중요한 것은 알겠지만 AI 를 어떻게 써서 회사에 어떻게 적용해야할지 모르겠다라는 단계에서
시작한 팀이었음

AI 를 어떻게 사용해서 가치창출을 할 수 있을까라는 고민이 끝나지 않은 상태에서 만들어진 팀

이런 고민들을 같이 했었어야 했음

이 고민을 한다는 건 경영자입장에서 AI 를 하고있는데 무언가 가져와라 하면 가져갈게 없는 것임

그런 stage 가 있었고 그 때 당시에 비해서는 훨씬 좋은 답을 가지고 있는거 같고 AI 가 어떤 의미인가라는
답을 찾는데 오래걸린것 같음

AI가 고객한테 어떻게 가치를 창출할 수 있을 것인가를 고민하는데 오래걸렸음

3년동안 많이 고민했던건

연구자로 살 것인가 개발자로 살것인가였음 

연구자라는건 어떻게 어떻게하면 되겠다라는 생각(가정)을 가지고 실험을해보고 입증을 하는 사람들이고

개발자라는건 과학적인 가설보다는 application 을 driven 하는 것 고객가치를 창출하는 것 제품을 디자인하고
만들어서 고객한테 팔고 돈을받는거라던지, 직접적으로 돈을 받지 않더라도 광고라던지 그런 가치에 대한 대가를 치루게
하는 이런걸 가능하게 하는 사람들임

이 2개가 독립적인듯 독립적이지 않다는게 지금의 결론임

이쪽분야는 연구자의 입장에서 봤을때는 연구자가 연구를 하려면 resource 가 많이 필요하고 데이터가 필요함

데이터라는건 사용자가 사용하면서 모이는 거임

대부분의 경우는 제품에서 데이터가 나오는 경우가 많음

AI 개발자라고 한다면은 engineering tuning 이 굉장히 중요하지만 이따금씩 기술적인 패러다임이 바뀜

이런 시기가 언제 있었냐면은 2018년 10월에 BERT 가 나왔음

지금은 많이 쓰고 있지만 그 당시에는 충격이었던게 BERT 이전만 해도 어떠한 모델을 만들고 싶다고하면
어떤 task 를 수행하고 싶다고 한다면 task 에 대한 데이터뿐만 아니라 모델을 만드는게 연구거리였음

성능을 올리고 싶다면 튜닝을 하게될텐데 80% 성능을 81%, 82% 올리는건데 같은 패러다임내에서는

80에서 81, 82로 올리는게 의미가 있겠지만 패러다임이 바뀌면 그건 상대가 안된다라는 것을 느낌

6~7년을 봤을 때 연구와 개발은 같이 갈 수 밖에 없음

패러다임 쉬프트가 일어날때는 gap closing 이 불가능한 변화가 일어나게됨

작년 같은 경우는 GPT-3 같은 모델의 등장으로 또 하나의 패러다임이 바뀌고 있는 것 같음

올해 초에 카이스트로 이직을 하게 되었는데 이직을 왜 하게 되었냐면?

회사보다 학교가 좋다기 보다는 이 직업이 해보고 싶었음

생각보다 깊은 고찰이 있었던것은 아니었음

작년에 네이버에 있을 때 그 때쯤에 네이버에서 매니저가 활석님이었고 활석님의 매니저가 성킴님이었음

이 두 분이 나가시게 되고 나간다음에 upstage 에 놀러갔다가 회사가 이런 방향으로 가려고 한다고 말을 해주시고
수업중에 MRC 를 맡아줄 수 있겠냐고 물어보셔서 상당히 좋은 기회가 될 것 같아서 수업을 맡게 되었음

## 3. MRC 수업 설계의도

1. NLP 가 아닌 MRC
   - NLP 가 중요하지만 이 수업은 NLP 가 아니라 MRC 다라고 생각했음
   - NLP 라는 걸 전부다 다루려고하면 너무 방대하기도 하고 특히나 top-down 보다는 bottom-up 이 낮다고
   생각했음
   - 정말 MRC 만 해야겠다고 생각했음
   - NLP 강의도 유튜브에 공개되어있음
2. 과학보다는 제품
   - 과학은 중요하지 않다라기보다는 이 수업에서는 과학을 배제하고 제품에 포커스를 하자
   - 수업을 같이 만드셨던 분들이 지난 학기때 수업을 만들었는데 이 수업을 듣고 다른건 몰라도되는데
   QA 시스템을 만들고싶다면 만들 수 있도록 있는 툴을 잘 활용해서 빨리 무언가 만들 수 있게 이게 가장
   중요한 목적이었음
3. Do not reinvent the wheel (feat. Hugging Face)
   - 공부하는 차원에서 reinvention 은 좋지만 그렇다고 하더라도 사용하는 것도 배워야 할 수 있는거라고 생각함
   - 수업이 상당히 depth 가 적다고 생각할 수 있음
   - 의도한바가 있었음

---

# 사전질문

![]({{site.url}}/assets/images/b0214d62.png)

직관이 중요하고 직관은 경험에서 나오는 것 같고 직관이 뭐냐라고 하면
흔히 얘기하는 insight 라던지 어떻게 어떤 방향으로 가야겠다는 생각인건데 경험상으로는 그 방향을
설정하는게 중요했던 것 같아요

그 다음으로 중요한건 애자일하게 일을 처리할 수 있을것인가

AI 라는건 uncertainty 를 항상 가져가는데 모델이 학습이 잘되는지는 모르는거고 거기에 불확실성이
있다고 한다면 이 불확실성을 견딜 수 있어야하고 이걸 직관으로 해쳐나가야하고

플러스 어떻게 이 직관을 빨리 실험해볼 수 있을까 아니면 아닌걸 빨리 확인할 수 있는게 중요하다고 봄

전통적인 software engineering 과 차이가 있다고 생각함

![]({{site.url}}/assets/images/79ae742e.png)

AI 가 워낙 빨리 바뀌니까 게임의 시즌이 바뀌는거라고 생각함

새로운 패로다임이 나오면 다 원점에서 시작하는 거임

지금까지 쌓아논 것은 도움이 되긴 하겠지만 여기서 중요한 것은 결국에는 지식자체보다는 지식을 슥듭할 수 있는
메타능력임 (공부하는 방법, 일을 처리하는 방법, 일을 organize 하는 방법)

이런 것들은 사실 조급함을 느낄 부분은 아닌 것 같음

전혀 reset 이 없는 level up 하듯이 이런 느낌보다는 좀있으면 또 reset 될거라서 그때되면 다 level1 이라서
그 때 다시 열심히하면 조급한 마음이 줄어들지 않을까 생각함

![]({{site.url}}/assets/images/249975d2.png)

요즘 관심을 갖는 주제는 화학반응 관련된 연구문제인데 가장 대표적인 예가 삼성전자에서 어떤 물질을 만들고 싶은데
화학적 notation 을 알고 가장 값이 싼 input 을 알고싶음

신약을 만드는 회사 같은 경우는 약을 만들기 위해서 필요한 input 이 있을 것임

이런 문제가 전통적으로는 사람의 지식을 통해서 접근했다면 이걸 input-output pair 로 봐서 머신러닝을
하고있음

여기서 한발짝 더나아가서 이런것들을 활용할 수 있는 지식(논문, 웹상에있는 지식)을 포함해서 많은 지식이 있고
이런 지식을 활용해서 과학적인 새로운 사실을 도출하거나 reasoning 을 할 때 활용할 수 있지 않을까 하는 
부분에 관심이 많음

챗봇같은 agent 들이 자연스럽게 얘기하려고 한다면 추론능력이 있어햐한다고 생각하는데 추론이라는게 과학적인
추론이냐 일상적인 추론이냐에 다를뿐인거지 전반적인 학계는 이런쪽으로 나가려고 하고있고 교수님도 이쪽으로
관심을 가지고 있음

![]({{site.url}}/assets/images/843d332c.png)

정말 못하신다고 했던 분들이 있었는데 결국 잘하시게 되더라

그래서 자신감을 가지시면 좋겠고 영어가 어려운 부분은 나중가면 스피킹이 어려운거 같고 reading 은 비교적
오랜시간이 아니고 충분히 노력하면 크게 문제는 없을거라고 생각함

![]({{site.url}}/assets/images/e5410487.png)

대학원생때는 비교적 졸업하고 취업을 잘하고 싶다는 동기가 컸던 것 같고 네이버에 있을때는 개발팀을 맡았었는데
scope 가 명확하다보니 개발은 잘되었었는데 맞지는 않았음

리스크가 크더라도 잘 되었을 때 큰 임팩트를 주는 주제가 더 원동력이 되는 것 같음

> 교수님 저도 회사에서 Verilog 하다 온거라 많이 공감하면서 들었습니다! 
AI가 발전하면서 FPGA도 함께 부상하고 있는데 교수님께서는 혹시 FPGA를 AI 연구에 함께 사용하고 계시나요??
그리고 앞으로 FPGA, Verilog 스킬셋을 AI와 함께 가져간다면 어떤 분야에 베네핏이 있을까요?

함께 사용하고 있지는 않고 상당히 관심있는 영역이긴 함

개인적인 생각으로는 아주 경쟁력이 있을거라고 생각함

> 우연히 Climbing Towards NLU: On Meaning, Form, and Understanding in the Age of 
> Data라는 논문에서 "머신이 단지 언어에 대한 패턴만을 학습할 뿐 언어를 이해하는 것이 아니다"라는 어찌보면 
> 당연하지만 약간 힘빠지는? 내용을 보게되었습니다. 태스크를 해결하기 위한 모델을 넘어서서 언어를 이해하는 
> 모델이 나올 수 있을지 교수님의 의견이 궁금합니다!

다른 생각을 가진 사람들이 있는 것임

이 논문은 결국에는 지금까지의 발전들이 패턴인식 아니냐 라는 side 고
2년전에 저한테 이 질문을 던졌다면 동의한다고 했을 것 같고 지금은 전적으로 동의하지 않음

그럴수도 있겠지만 그렇지 않을 수 있다고 생각함

지금은 큰 변화가 있을 수 있겠다는 생각이 듦

AI 를 연구하고 이쪽에서 일을 하기에 exciting 한 시대라고 생각함

![]({{site.url}}/assets/images/a9f9eb06.png)

seominjoon@gmail.com

질문들을 봤을 때 예전에 가졌던 질문들이라 혼자가 아니라는 점 말씀드리고 잘 해내실거라고 생각합니다.

